<!DOCTYPE HTML>
<!--
	   Stellar by HTML5 UP
	   html5up.net | @ajlkn
	   Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
	   Used for USR 2023
   -->
<html>

    <head>
	      <title>USR 2023 workshop</title>
	      <meta charset="utf-8" />
	      <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	      <link rel="stylesheet" href="assets/css/main.css" />
	      <noscript>
		        <link rel="stylesheet" href="assets/css/noscript.css" />
	      </noscript>
	      <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon" />
    </head>

    <body class="is-preload">

	      <!-- Wrapper -->
	      <div id="wrapper">

		        <!-- Header -->
		        <header id="header" class="alt">
			          <span class="logo"><img width="500px" src="images/logo.png" alt="" /></span>
			          <h1>ICRA 2023 Workshop on</br> <strong>Unconventional spatial representations</strong></br>Opportunities for
				            robotics
			          </h1>
			          <p>2023 IEEE International Conference on Robotics and Automation (ICRA)</br>May 29, 2023 London, UK</p>
		        </header>

		        <!-- Nav -->
		        <nav id="nav">
			          <ul>
				            <li><a href="#intro" class="active">About the workshop</a></li>
				            <li><a href="#registration" class="active">Call for Papers</a></li>
				            <li><a href="#participation" class="active">Participation</a></li>
				            <li><a href="#speakers" class="active">Program</a></li>
				            <li><a href="#organizers">Organizers</a></li>
			          </ul>
		        </nav>

		        <!-- Main -->
		        <div id="main">

			          <!-- Introduction -->
			          <section id="intro" class="main">
				            <div class="spotlight">
					              <div class="content">
						                <header class="major">
							                  <h2>The successful operation of any autonomous agent heavily depends on capturing and
								                    understanding the complex nature of the environment, including its volatile or implicit
								                    characteristics.</h2>
						                </header>
						                <p>Even though robotics is undergoing rapid development, several application areas are still
							                  hindered by limitations in how environmental information is represented. Qualities that
							                  might be missing from state-of-the-art representations include the relations between
							                  environment features, meta-information describing the quality and applicability of the
							                  representation itself, or condition-dependent characteristics.
							  </br></br>
                The goal of the workshop is to further advance in the direction of developing unconventional, possibly richer and informative, environment representations for autonomous robots, building on recent results and extending them beyond the boundaries of methods currently used in robotics. Here, “unconventional” refers both to the representations (e.g., beyond grids and point clouds) and to the features of the environments that are included in the model.
							  </br></br>
							  We bring together researchers with diverse and versatile expertise and backgrounds to
							  achieve this goal. Through gathering such a group, we aim to fulfill the following three
							  objectives:
						                </p>
						                <ul>
							                  <li>We aim to provide a platform to formulate and communicate the most urgent needs for
								                    representations in robotics.</li>
							                  <li>We want to expose the robotic community to recent developments in relevant correlated
								                    fields such as AI and cognitive science.</li>
							                  <li>As a result, we want to pave the road for developing novel representations reaching
								                    beyond the state-of-the-art.</li>
						                </ul>
						                <ul class="actions">
							                  <li><a href="details.html" class="button">Learn More</a></li>
						                </ul>
					              </div>
					              <!--span class="image"><img src="images/lhmp-spencer-2.png" alt="" /></span-->
				            </div>
			          </section>

			          <section id="registration" class="main style1">
				            <div class="container">
					              <header class="major">
						                <h2>Call for Papers</h2>
					              </header>

					              During this workshop, we will also hold a poster session to present recent developments.
					              Thus we invite you to submit your novel contribution covering one of the following topics:

					              <ul>
						                <li>Representations of challenging environments (i.e., underwater and space environments,
							                  heavily crowded environments).</li>
						                <li>Implicit environment representations based on neural networks and other machine learning
							                  models.</li>
						                <li>Representations of other agents (humans and robots) that are operating in the same
							                  environment.</li>
						                <li>Representations of implicit environmental features (points of interest, "attention
							                  grabbers", etc.).</li>
						                <li>Representations of map meta information (quality, accuracy, etc.).</li>
						                <li>Representations for volatile quantities such as gas concentrations.</li>
                            <li>Representations for context-aware motion planners. </li>
                            <li>Simulations, digital twins, and sim2real.</li>
					              </ul>

                        <h3>Guide for authors</h3>
                        <p>
                            Please submit an extended abstract of up to 4 pages, including references, to the workshop chair at <a href="mailto:tomasz.kucner@aalto.fi?subject=USR workshop submission">tomasz.kucner@aalto.fi</a>.

                            For the paper template, please use the standard <a href="https://www.ieee.org/conferences/publishing/templates.html">IEEE conference template</a>.

                            Submissions that are re-elaborations of recently published papers are welcome.
                            The workshop will not have archival proceedings.  

                            All the submitted papers will undergo review by the organising committee and will be accepted based on their quality, merit and timeliness.
                        </p>

                        <h3>Important dates &ndash; regular submission</h3>
                        <ul>
                            <li>Deadline for submission: <b>14th of March 2023</b></li>
                            <li>Notification of acceptance: <b>28th of March 2023</b></li>
                            <li>Deadline for final paper submission: <b>15th of May 2023</b></li>
                        </ul>

                        <h3>Important dates &ndash; breaking results</h3>
                        <ul>
                            <li>Deadline for submission: 14th of April 2023</li>
                            <li>Notification of acceptance: 28th of April 2023</li>
                            <li>Deadline for final paper submission: 15th of May 2023</li>
                        </ul>

                        <h3>Publication and dissemination</h3>

                        The accepted papers will be presented during a poster session accompanying the workshop during ICRA 2023.
                        After the workshop, the papers with accompanying posters will be available on the workshop's web page.


			          </section>


			          <section id="participation" class="main style1">
				            <div class="container">
					              <header class="major">
						                <h2>Participation</h2>
					              </header>
					              The key part of the conference will be held in person at the conference venue. However, for improved
					              participation and dissemination the key talks will be streamed via zoom and they will be later
					              available on the YouTube channel of the orgnisers.
					              <!-- <p>Online participation in this workshop is free of charge. To join the virtual workshop, use
					                   this link: <a href="xxxxxxx">xxxxxxxxxxxxxxx</a>. -->
					      </br></br>
					      For in-person participation, please follow the <a href="https://www.icra2023.org/welcome">ICRA
					          conference and workshops registration page</a>.</p>

				            </div>
			          </section>

                <!-- -- -->
			          <section id="speakers" class="main style1">
				            <div class="container">
					              <header class="major">
						                <h2>Invited speakers</h2>
					              </header>
					              <div class="box alt">
						                <div class="row gtr-uniform">
							                  <div class="col-2">
								                    <span class="image fit"><img src="images/Speakers/yvan.jpg" alt="" /></span>
								                    <h5><a href="https://www.edinburgh-robotics.org/academics/yvan-petillot"><strong>Yvan Petillot</strong>,</br>
                                        Heriot-Watt University</a></h5>
							                  </div>
							                  <div class="col-2">
								                    <span class="image fit"><img src="images/Speakers/teresa.jpg" alt="" /></span>
								                    <h5> <a href="https://profiles.uts.edu.au/Teresa.VidalCalleja"><strong>Teresa Vidal Calleja</strong>,</br>
                                        University of Technology Sydney</a></h5>
							                  </div>
                                <div class="col-2">
								                    <span class="image fit"><img src="images/Speakers/hyuntaek.jpg" alt="" /></span>
								                    <h5> <a><strong>Hyun-Taek Choi</strong>,</br>
                                        Korea Research Institute of Ships and Ocean Engineering</a></h5>
							                  </div>
                                <div class="col-2">
								                    <span class="image fit"><img src="images/Speakers/anna.jpg" alt="" /></span>
								                    <h5> <a><strong>Anna Mannucci</strong>,</br>
                                        Robert Bosch GmbH</a></h5>
							                  </div>
                                <div class="col-2">
								                    <span class="image fit"><img src="images/Speakers/luigi.jpg" alt="" /></span>
								                    <h5> <a><strong>Luigi Palmieri</strong>,</br>
                                        Robert Bosch GmbH</a></h5>
							                  </div>                              
							                  <div class="col-2">
								                    <span class="image fit"><img src="images/Speakers/laura.jpg" alt="" /></span>
								                    <h5> <a><strong>Laura Fiorini</strong>,</br>
                                        University of Florence</a></h5>
							                  </div>
							                  <div class="col-2">
								                    <span class="image fit"><img src="images/Speakers/jole.jpg" alt="" /></span>
								                    <h5> <a href="http://ai.uos.ac.kr"><strong>Jaeho Lee</strong>,<br>
                                        University of Seoul</br></a></h5>
							                  </div>
							                  <div class="col-2">
								                    <span class="image fit"><img src="images/Speakers/hiroshi.jpg" alt="" /></span>
								                    <h5> <a><strong>Hiroshi Ishida</strong>,</br>
                                        Tokyo University of Agriculture</a></h5>
							                  </div>
                                <div class="col-2">
								                    <span class="image fit"><img src="images/Speakers/haruka.jpg" alt="" /></span>
								                    <h5> <a><strong>Haruka Matsukura</strong>,</br>
                                        University of Electro-Communications</a></h5>
							                  </div>
							                  <div class="col-2">
								                    <span class="image fit"><img src="images/Speakers/edson.jpg" alt="" /></span>
								                    <h5> <a href="https://www.inf.ufrgs.br/~prestes/site/Welcome.html"><strong>Edson Prestes</strong>,</br>
                                        Universidade Federal do Rio Grande do Sul</a></h5>
							                  </div>
                                <div class="col-2">
								                    <span class="image fit"><img src="images/Speakers/ryan.jpg" alt="" /></span>
								                    <h5> <a href="http://www.ryannealsmith.com"><strong>Ryan Smith</strong>,</br>
                                        Fort Lewis College</a></h5>
							                  </div>
						                </div>
					              </div>
					      </br>


                <!-- -- -->
                
			          <section id="program" class="main style1">
				            <div class="container">
					              <header class="major">
						                <h2>Program (tentative)</h2>
					              </header>

					              <p>
                            Please note that the program below is tentative, and that the order of the speakers is likely to change.
                            (Click a row to expand the abstract.)
                        </p>

					              <div class="table-wrapper">
						                <table>
							                  <thead>
								                    <tr>
									                      <th>Time<br>(London Local Time)</th>
									                      <th>Speaker</th>
									                      <th>Topic</th>
								                    </tr>
							                  </thead>
							                  <tbody>
								                    <tr>
									                      <td>9:00 - 9:10 am </td>
									                      <td>Organizers</td>
									                      <td>Welcome and Introduction</td>
								                    </tr>
                                    <tr onClick='toggleRow(this)'>
									                      <td>9:10 - 9:35 am </td>
									                      <td>
                                            <a><strong>Laura Fiorini</strong><br>
                                                University of Florence</a>
                                        </td>
									                      <td>Personalized HRI through advanced behavioural models for application in healthcare domains: Where we are and what we need to</td>
									                      <td class='expanded-row-content hide-row'>Abstract: Social robots are entering our houses and hospitals, therefore they should be endowed with advanced and personalised interaction capabilities thus to adapt to the dynamic external environments and the changing needs of frail citizens. Additionally, social robots should be able to cooperate interactively with formal caregivers as well as clinicians thus shifting from a care model where the frail user interacts with the robot to care models where also the clinicians/formal caregivers are also involved at different levels, according to the application. Indeed, the data acquired from the robots can be used by the robots to personalise the interaction and by the clinician to monitor the status of the users.</td>
								                    </tr>
								                    <tr onClick='toggleRow(this)'>
									                      <td>9:35 - 10:00 am
									                          <td>
                                                <a href="University of Technology Sydney"><strong>Teresa Vidal Calleja</strong><br>
                                                    University of Technology Sydney</a>
									                              <td>Physics driven, continuous and probabilistic representations for localisation, mapping and planning</td>
									                              <td class='expanded-row-content hide-row'>
                                                    Abstract: 
                                                    In this talk, first I will go through our work on faithful Euclidean distance field estimation for localisation, mapping and planning using a continuous and probabilistic implicit surface representation (Log-GPIS). Log-GPIS aims to approximate closely the solution of the regularised Eikonal equation to estimate the distance field and its gradient enabling surface reconstruction, localisation and obstacle avoidance.  Then, I will introduce our recent work on global localisation based on continuous magnetic vector fields that rely on a divergence-free kernel and our crowd prediction approach that enforces the conservation of people density. Simulations and experimental results will be used to show the performance of these representations.
                                                </td>
								                    </tr>
								                    <tr onClick='toggleRow(this)'>
									                      <td>10:00 - 10:25 am
									                          <td>
                                                <a><strong>Hyun-Taek Choi</strong><br>
                                                    Korea Research Institute of Ships and Ocean Engineering</a>
                                            </td>
									                          <td>Understanding and Representing the Sea environment for Autonomous Ship Navigation</td>
									                          <td class='expanded-row-content hide-row'>
													                      Abstract: Navigation in robotics has seen significant progress in recent years, with advancements in various technologies such as SLAM (Simultaneous Localization and Mapping). However, implementing these technologies in real environments for extended periods of time with both robustness and flexibility remains a challenge. It is possible that these established frameworks may be leading us to overlook real problems. Although the ocean may not be appropriate for pure SLAM, by understanding the environment and our goals precisely, the problem we need to solve does not have to be unnecessarily difficult. In this context, the environment includes not only wide areas of the ocean with strong sunlight and dense fog but also the temporal conditions of control cycles necessary for ship navigation, peripheral conditions that change according to the navigation route of the ship, and the conditions imposed by international law and conventions in the shipping industry. This presentation introduces our ongoing research on the situation awareness system of autonomous ships, which is being developed due to commercial demand. We will show you our data fusion structure using mathematical and heuristic methods, along with deep-learning-based detection algorithms for each sensor. In conclusion, we keep reminding ourselves that our goal is to identify any collision risks rather than detecting small objects near the horizon. To successfully apply autonomous systems in various applications, it is beneficial to take a heuristic approach, accurately understanding the system and the purpose we pursue. 
											                      </td>
								                    </tr>
								                    <tr>
									                      <td>10:25 - 10:50 am </td>
									                      <td colspan="2"> <b>Poster session</b> and coffee break</td>
								                    </tr>
								                    <tr>
									                      <td>10:50 - 11:35 am </td>
									                      <td><b>"World Cafe" discussion</b></td>
									                      <td>Topics TBA</td>
								                    </tr>
								                    <tr onClick='toggleRow(this)'>
									                      <td>11:35 - 12:00 pm
									                          <td>
                                                <a href="https://www.edinburgh-robotics.org/academics/yvan-petillot"><strong>Yvan Petillot</strong><br> Heriot-Watt University</a>
                                                <!-- <strong><a href="XXXX">Speaker 1</a></strong>, Affiliation</td> -->
									                              <td>Map representations for remote marine operations, what can we get? What do we need? How do we get there?</td>
									                              <td class='expanded-row-content hide-row'>Abstract: TBA</td>
								                    </tr>
                                    <tr onClick='toggleRow(this)'>
									                      <td>12:00 - 12:25 pm
									                          <td>
                                                <a><strong>Anna Mannucci & Luigi Palmieri</strong><br>
                                                    Robert Bosch GmbH</a>
                                            </td>
									                          <td>

                                                Towards Context-aware Predictive Planning in Complex Environments</td>
									                          <td class='expanded-row-content hide-row'>Abstract: Computing safe navigation policies for wheeled mobile robots navigating in densely cluttered and crowded spaces is a difficult task due to several factors, e.g., perception noise, system models mismatch, high uncertainty of human future behaviors. The latter being influenced not only by other surrounding humans but also by environmental properties. In these settings, classical reactive approaches often result in an overly cautious robot that fails to produce a feasible, safe path in the crowd, or plans a large, sub-optimal, perhaps oscillating detour to avoid hindrances. Additionally, several contextual cues may influence robots' motion, e.g., semantic relationships between objects in the environment, activity patterns and social relations: considering them in the decision-making phase is fundamental for improving the overall robot operation efficiency. Due to those several factors, a unique solution to fully solve robot navigation in cluttered, crowded and dynamic environments is still far ahead of us. The problem is even more challenging when considering fleets of robots. In this talk, we will present several predictive robot motion planning approaches and architectures developed to solve the issue. Particularly demanding is the type of environment representations used in those architectures for computing the final robot policies. 
                                                <p>
                                                    We will show how the quest for a safe and efficient robot navigation policy requires not only the improvements of several planning sub-components, but also the study of proper architectures that consider contextual proprieties of the environment.</td>
								                    </tr>
								                    <tr>
									                      <td>12:25 - 1:55 apm </td>
									                      <td colspan="2">Lunch Break</td>
								                    </tr>
								                    <tr onClick='toggleRow(this)'>
									                      <td>1:55 - 2:20 pm
                                            <td>
                                                <a><strong>Jaeho Lee</strong></br>
                                            </td>
									                          <td>Title</td>
									                          <td class='expanded-row-content hide-row'>Abstract: TBA</td>
								                    </tr>
								                    <tr onClick='toggleRow(this)'>
									                      <td>2:20 - 2:45 pm
                                            <td>
                                                <a><strong>Hiroshi Ishida</strong></br>
                                                    Tokyo University of Agriculture</a><br>
                                                <a><strong>Haruka Matsukura</strong></br>
                                                    University of Electro-Communications</a>
                                            </td>
									                          <td>
                                                Olfactory landscapes of the world and challenges to digitize them
                                            </td>
									                          <td class='expanded-row-content hide-row'>Abstract:
                                                Olfaction is the sense of smell that enables organisms to detect volatile chemical compounds in the air and analyze their implications, such as food rottenness and homing orientation. Although attempts to provide robots with such a sensor modality have not always been successful, an increasing number of research efforts are being made as a result of advances in sensor technologies. Smell source localization has been one of the main topics in mobile robot olfaction. Some animals can locate food by tracking its smell. To accomplish smell tracking is very challenging because the aerial trail of smell is highly unstable. However, some successful results of gas source localization are reported using stochastic approaches, e.g., a particle filter. This talk also covers some recent topics including super-resolution for gas distribution mapping and digital reproduction of smells.</td>
								                    </tr>
								                    <tr onClick='toggleRow(this)'>
									                      <td>2:45 - 3:10 pm
                                            <td>
                                                <a href="https://www.inf.ufrgs.br/~prestes/site/Welcome.html"><strong>Edson Prestes</strong></br>
                                                    Universidade Federal do Rio Grande do Sul</a>
                                            </td>									                         
									                          <td>IEEE Ontological Standard for Ethically Driven Robotics and Automation Systems</td>
									                          <td class='expanded-row-content hide-row'>Abstract: Artificial Intelligence and Robotics can bring many benefits to humanity. There are several examples created by our community that show how AI and robotics can be used to attain the United Nations Sustainable Development Goals. However, despite all these benefits, there are some applications that show the devastating power of AI and Robotics,
                                                posing serious risks to our fundamental rights that go beyond privacy issues and that mainly affect vulnerable and underprivileged communities. Therefore, global society has put a lot of energy in creating soft and hard laws to create some barriers in these developments to ensure that AI and robotics based applications are used for good and not the other way around.<p>
                                                In this talk, I will discuss the recently published "IEEE Ontological Standard for Ethically Driven Robotics and Automation Systems" which aims mainly to assist in the development of ethically oriented methodologies for the design of robots and automation systems. However, this standard can be used in many ways, for example as the core of a platform for multilateral organisations to govern the domain.
                                            </td>
								                    </tr>
								                    <tr onClick='toggleRow(this)'>
									                      <td>3:10 - 3:35 pm
                                            <td>
                                                <a href="http://www.ryannealsmith.com"><strong>Ryan Smith</strong></br>
                                                    Fort Lewis College</a></h5>
                                            </td>
									                          <td>Hard Miles without Hard Miles</td>
									                          <td class='expanded-row-content hide-row'>Abstract: It is miserable and costly to drive vast numbers of miles in the hope of experiencing those elusive edge/corner cases. Indeed, in many industrial and urban application domains, it is not even possible to do this in advance of substantive deployments. We will offer an alternative, less-dreary vista. Using composite scene synthesis and weather synthesis, software-in-the-loop tightly integrated with Sim, and reinforcement learning, we exponentiate the value of a small-seed dataset of benign autonomy runs as a precursor for a site-wide/domain-specific validation and verification.</td>
								                    </tr>
								                    <tr>
									                      <td>3:35 - 4:05 pm </td>
									                      <td colspan="2"><b>Poster session</b> and coffee break</td>
								                    </tr>
								                    <tr>
									                      <td>4:05 - 4:50 pm </td>
									                      <td><b>Panel discussion</b></td>
									                      <td>Topics TBA</td>
								                    </tr>
								                    <tr>
									                      <td>4:50 - 5:00 pm </td>
									                      <td>Organizers</td>
									                      <td>Closing</td>
								                    </tr>
							                  </tbody>
						                </table>
					              </div>


				            </div>
			          </section>




			          <section id="organizers" class="main style1">
				            <div class="container">
					              <header class="major special">
						                <h2>Organizers</h2>
					              </header>
					              <div class="box alt">
						                <div class="row gtr-uniform">
							                  <div class="col-2">
								                    <span class="image fit"><img src="images/Organizers/tzkr.jpg" alt="" /></span>
								                    <h5> <a href="https://people.aalto.fi/tomasz.kucner"><strong>Tomasz Piotr
											                  Kucner</strong>,</br>
										                    Aalto Unviersity</a></h5>
							                  </div>
							                  <div class="col-2">
								                    <span class="image fit"><img src="images/Organizers/foai.jpg" alt="" /></span>
								                    <h5><a href="https://amigoni.faculty.polimi.it/"><strong>Francesco
											                  Amigoni</strong>,</br> Politecnico di Milano</a></h5>
							                  </div>
							                  <div class="col-2">
								                    <span class="image fit"><img src="images/Organizers/molo.png" alt="" /></span>
								                    <h5> <a href="https://www.unimi.it/it/ugov/person/matteo-luperto"><strong>Matteo
											                  Luperto</strong>,</br> Università degli
										                    Studi di Milano</a></h5>
							                  </div>
							                  <div class="col-2">
								                    <span class="image fit"><img src="images/Organizers/mnmn.jpg" alt="" /></span>
								                    <h5> <a href="https://www.oru.se/english/employee/martin_magnusson"><strong>Martin
											                  Magnusson</strong>,</br> Örebro University</a></h5>
							                  </div>
							                  <div class="col-2">
								                    <span class="image fit"><img src="images/Organizers/fova.jpg" alt="" /></span>
								                    <h5> <a href="https://people.aalto.fi/francesco.verdoja"><strong>Francesco
											                  Verdoja</strong>,</br> Aalto Unviersity</a></h5>
							                  </div>
							                  <div class="col-2">
								                    <span class="image fit"><img src="images/Organizers/jnfl.jpeg" alt="" /></span>
								                    <h5> <a href="https://robotics.fel.cvut.cz/faigl/"><strong>Jan Faigl</strong>,</br>
										                    Czech Technical University in Prague</a></h5>
							                  </div>
						                </div>
					              </div>
					      </br>

					      <header class="major special">
						        <h2>Supporting IEEE RAS technical committees</h2>
					      </header>
					      <div class="row">
						        <div class="col-2 col-12-medium">
							          <span class="image fit"><img src="images/RAS-logo.png" alt="" /></span>
						        </div>
						        <div class="col-8 col-12-medium">
							          <ul>
								            <li><a href="https://www.ieee-ras.org/cognitive-robotics">Technical
										            committee on Cognitive Robotics</a></li>
								            <li><a href="https://www.ieee-ras.org/performance-evaluation">Technical
										            committee on Performance Evaluation & Benchmarking of Robotic and Automation
										            Systems</a></li>
								            <li><a href="https://www.ieee-ras.org/marine-robotics">Technical committee on Marine
										            Robotics</a></li>
							          </ul>
						        </div>
					      </div>

					      <header class="major special">
						        <h2>Supported by</h2>
					      </header>
					      <div class="box alt">
						        <div class="row gtr-uniform">
							          <div class="col-2"><span class="image fit"><img style="border-radius:2px"
										                                                    src="images/Affiliations/aalto.png" alt="" /></span></div>
							          <div class="col-2"><span class="image fit"><img style="border-radius:2px"
										                                                    src="images/Affiliations/fcai-logo.png" alt="" /></span></div>
							          <div class="col-2"><span class="image fit"><img style="border-radius:2px"
										                                                    src="images/Affiliations/1200px-Örebro_Universitet.svg.png" alt="" /></span>
							          </div>
							          <div class="col-2"><span class="image fit"><img style="border-radius:2px"
										                                                    src="images/Affiliations/Logo_Politecnico_Milano.png" alt="" /></span></div>
							          <div class="col-2"><span class="image fit"><img style="border-radius:2px"
										                                                    src="images/Affiliations/uni_mi.jpg" alt="" /></span></div>
							          <div class="col-2"><span class="image fit"><img style="border-radius:2px"
										                                                    src="images/Affiliations/logo_cvut_en_doplnkova_verze.jpg" alt="" /></span>
							          </div>
						        </div>
					      </div>
				            </div>
			          </section>

			          <!--

							       <section id="cta" class="main special">
								     <header class="major">
									   <h2>Congue imperdiet</h2>
									   <p>Donec imperdiet consequat consequat. Suspendisse feugiat congue<br />
									   posuere. Nulla massa urna, fermentum eget quam aliquet.</p>
								     </header>
								     <footer class="major">
									   <ul class="actions special">
										 <li><a href="generic.html" class="button primary">Get Started</a></li>
										 <li><a href="generic.html" class="button">Learn More</a></li>
									   </ul>
								     </footer>
							       </section>
                   -->

		                </div>

		                <!-- Footer -->
		                <footer id="footer">
			                  <section>
				                    <h2>Get in touch</h2>
				                    <p>Please feel free to send us an <a href="mailto:tomasz.kucner@aalto.fi?Subject=Workshop%20USR"
						                                                     target="_top">e-mail</a>, if you have any questions regarding this workshop.</p>
			                  </section>
			                  <!-- 
						                 <section>
							               <h2>Etiam feugiat</h2>
							               <dl class="alt">
								             <dt>Address</dt>
								             <dd>1234 Somewhere Road &bull; Nashville, TN 00000 &bull; USA</dd>
								             <dt>Phone</dt>
								             <dd>(000) 000-0000 x 0000</dd>
								             <dt>Email</dt>
								             <dd><a href="#">information@untitled.tld</a></dd>
							               </dl>
							               <ul class="icons">
								             <li><a href="#" class="icon brands fa-twitter alt"><span class="label">Twitter</span></a></li>
								             <li><a href="#" class="icon brands fa-facebook-f alt"><span class="label">Facebook</span></a></li>
								             <li><a href="#" class="icon brands fa-instagram alt"><span class="label">Instagram</span></a></li>
								             <li><a href="#" class="icon brands fa-github alt"><span class="label">GitHub</span></a></li>
								             <li><a href="#" class="icon brands fa-dribbble alt"><span class="label">Dribbble</span></a></li>
							               </ul>
						                 </section>
						               -->
			                  <p class="copyright">&copy; Tomasz Kucner. All rights reserved. Design: <a href="https://html5up.net">HTML5
					                  UP</a>.</p>
		                </footer>

	                  </div>

	                  <!-- Scripts -->
	                  <script src="assets/js/jquery.min.js"></script>
	                  <script src="assets/js/jquery.scrollex.min.js"></script>
	                  <script src="assets/js/jquery.scrolly.min.js"></script>
	                  <script src="assets/js/browser.min.js"></script>
	                  <script src="assets/js/breakpoints.min.js"></script>
	                  <script src="assets/js/util.js"></script>
	                  <script src="assets/js/main.js"></script>

	                  <script>
		                 const toggleRow = (element) => {
			                   element.getElementsByClassName('expanded-row-content')[0].classList.toggle('hide-row');
			                   console.log(event);
		                 }
	                  </script>

</body>

</html>
